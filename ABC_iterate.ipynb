{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import joblib\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or '3' to suppress all messages\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "label_encoder = LabelEncoder()\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_dict_to_pickle(dictionary, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(dictionary, file)\n",
    "\n",
    "def load_dict_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = './data/data_by_table/pre_24h_data_1217.csv'\n",
    "model_A_dict_file_path = './model/model_A_dict.pkl'\n",
    "model_B_dict_file_path = './model/model_B_dict.pkl'\n",
    "model_c_path ='./model/1219test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[20:51:58] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_21wtzqx5vy/croot/xgboost-split_1675457780668/work/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MLPRegressor from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_A_dict = load_dict_from_pickle(model_A_dict_file_path)\n",
    "model_B_dict = load_dict_from_pickle(model_B_dict_file_path)\n",
    "model_C = load_model('./model/1219test.h5')\n",
    "scaler_C = joblib.load('./model/C_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'charttime', 'before_weaning_hr', 'stay_id', 'subject_id',\n",
      "       'O2_flow', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2',\n",
      "       'peep', 'fio2', 'tidal_volume_observed', 'respiratory_rate_set',\n",
      "       'plateau_pressure', 'ventilator_mode', 'GCS', 'hadm_id', 'age_now',\n",
      "       'gender', 'insurance', 'race', 'admission_type', 'first_careunit',\n",
      "       'weight_kg', 'height_cm', 'tobacco', 'label', 'Rev_h', 'dod_h', 'RSBI',\n",
      "       'minute_ventilation', 'ventilator_mode_group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "raw_data_df = pd.read_csv(raw_data_path)\n",
    "\n",
    "print(raw_data_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define op function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_A_inference(test_change_label_value_aug_df, model_A_dict, feature, feature_columns, prefix):\n",
    "    # Initialize an empty DataFrame to store the results\n",
    "    regression_results = pd.DataFrame(index=test_change_label_value_aug_df.index)\n",
    "\n",
    "    classifier = model_A_dict[feature]['classifier']\n",
    "    regressor = model_A_dict[feature]['regressor']\n",
    "    scaler_classifier = model_A_dict[feature]['scaler_classifier']\n",
    "    scaler_regressor = model_A_dict[feature]['scaler_regressor']\n",
    "\n",
    "    test_scaled_df = scaler_classifier.transform(test_change_label_value_aug_df[feature_columns])\n",
    "\n",
    "    # Make classification predictions\n",
    "    classification_predict = classifier.predict(test_scaled_df)\n",
    "    if(classification_predict[0] == 0):\n",
    "        test_change_label_value_aug_df.reset_index\n",
    "        return test_change_label_value_aug_df[feature].values[0]\n",
    "    #print_classification_metrics(test_change_label_value_aug_df[f'{feature}_change_label'], classification_predict, prefix)\n",
    "\n",
    "    # Filter rows based on classification prediction\n",
    "    classification_0_rows = test_change_label_value_aug_df[classification_predict == 0]\n",
    "\n",
    "    # Set regression_predict for rows with classification 0\n",
    "    regression_results.loc[classification_0_rows.index, f'{feature}_regression_predict'] = \\\n",
    "        test_change_label_value_aug_df.loc[classification_0_rows.index, f'{feature}_prev_1h']\n",
    "\n",
    "    # Set regression_predict for rows with classification 1 using regressor predictions\n",
    "    classification_1_rows = test_change_label_value_aug_df[classification_predict == 1]\n",
    "    test_scaled_df = scaler_regressor.transform(test_change_label_value_aug_df.loc[classification_1_rows.index, feature_columns])\n",
    "    regression_predictions = regressor.predict(test_scaled_df)\n",
    "    regression_results.loc[classification_1_rows.index, f'{feature}_regression_predict'] = regression_predictions\n",
    "    return regression_predictions\n",
    "    \n",
    "    #print_regression_metrics(test_change_label_value_aug_df[feature], regression_results, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A_one_row_data(df, stay_id, before_weaning_hr):\n",
    "    # Filter the DataFrame based on stay_id and before_weaning_hr\n",
    "    filtered_df = df[(df['stay_id'] == stay_id) & (df['before_weaning_hr'] == before_weaning_hr)].copy()\n",
    "\n",
    "    # Select the desired feature columns\n",
    "    feature_columns = [\n",
    "        'before_weaning_hr', 'age_now', 'weight_kg',\n",
    "        'height_cm', 'tobacco', 'heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate',\n",
    "        'tidal_volume_observed', 'RSBI', 'minute_ventilation', 'peep', 'fio2',\n",
    "        'respiratory_rate_set', 'plateau_pressure'\n",
    "    ]\n",
    "\n",
    "    # Add columns for previous 1-hour values\n",
    "    prev_1h_columns = [\n",
    "        'heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate',\n",
    "        'tidal_volume_observed', 'RSBI', 'minute_ventilation', 'peep', 'fio2',\n",
    "        'respiratory_rate_set', 'plateau_pressure'\n",
    "    ]\n",
    "\n",
    "    for col in prev_1h_columns:\n",
    "        col_name_prev_1h = f'{col}_prev_1h'\n",
    "        # Get the previous 1-hour value from the same stay_id but at before_weaning_hr + 1\n",
    "        filtered_df[col_name_prev_1h] = df[(df['stay_id'] == stay_id) & (df['before_weaning_hr'] == before_weaning_hr + 1)][col].values\n",
    "\n",
    "    for col in prev_1h_columns:\n",
    "        col_name_prev_1h = f'{col}_prev_2h'\n",
    "        # Get the previous 1-hour value from the same stay_id but at before_weaning_hr + 1\n",
    "        filtered_df[col_name_prev_1h] = df[(df['stay_id'] == stay_id) & (df['before_weaning_hr'] == before_weaning_hr + 2)][col].values\n",
    "\n",
    "    # Return the final DataFrame with selected columns\n",
    "    return filtered_df\n",
    "\n",
    "def get_B_one_row_data(df, stay_id, before_weaning_hr, features):\n",
    "    # Filter the DataFrame based on stay_id and before_weaning_hr\n",
    "    filtered_df = df[(df['stay_id'] == stay_id) & (df['before_weaning_hr'] == before_weaning_hr)].copy()\n",
    "\n",
    "    # Select the desired feature columns\n",
    "    feature_columns = [\n",
    "        'before_weaning_hr', 'age_now', 'weight_kg',\n",
    "        'height_cm', 'tobacco', 'heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate',\n",
    "        'tidal_volume_observed', 'RSBI', 'minute_ventilation', 'peep', 'fio2',\n",
    "        'respiratory_rate_set', 'plateau_pressure'\n",
    "    ]\n",
    "\n",
    "    # Add columns for previous 1-hour values\n",
    "    prev_1h_columns = [\n",
    "        'heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate',\n",
    "        'tidal_volume_observed', 'RSBI', 'minute_ventilation', 'peep', 'fio2',\n",
    "        'respiratory_rate_set', 'plateau_pressure'\n",
    "    ]\n",
    "\n",
    "    for col in prev_1h_columns:\n",
    "        col_name_prev_1h = f'{col}_prev_1h'\n",
    "        # Get the previous 1-hour value from the same stay_id but at before_weaning_hr + 1\n",
    "        filtered_df[col_name_prev_1h] = df[(df['stay_id'] == stay_id) & (df['before_weaning_hr'] == before_weaning_hr + 1)][col].values\n",
    "\n",
    "    for col in prev_1h_columns:\n",
    "        col_name_prev_1h = f'{col}_prev_2h'\n",
    "        # Get the previous 1-hour value from the same stay_id but at before_weaning_hr + 1\n",
    "        filtered_df[col_name_prev_1h] = df[(df['stay_id'] == stay_id) & (df['before_weaning_hr'] == before_weaning_hr + 2)][col].values\n",
    "\n",
    "    # Return the final DataFrame with selected columns\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'before_weaning_hr', 'age_now', 'weight_kg',\n",
    "    'height_cm', 'tobacco', 'heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', 'tidal_volume_observed', 'RSBI',\n",
    "    'minute_ventilation', 'heart_rate_prev_1h', 'sbp_prev_1h', 'dbp_prev_1h', 'mbp_prev_1h', 'spo2_prev_1h',\n",
    "    'resp_rate_prev_1h', 'tidal_volume_observed_prev_1h', 'RSBI_prev_1h', 'minute_ventilation_prev_1h', \n",
    "    'peep_prev_1h', 'fio2_prev_1h', 'respiratory_rate_set_prev_1h', 'plateau_pressure_prev_1h',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['heart_rate_prev_1h', 'sbp_prev_1h',\n",
    " 'dbp_prev_1h', 'mbp_prev_1h', 'spo2_prev_1h',\n",
    " 'resp_rate_prev_1h', 'tidal_volume_observed_prev_1h',\n",
    " 'RSBI_prev_1h', 'minute_ventilation_prev_1h', 'peep_prev_1h', \n",
    " 'fio2_prev_1h', 'respiratory_rate_set_prev_1h', 'plateau_pressure_prev_1h']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A test Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0\n"
     ]
    }
   ],
   "source": [
    "result_df = get_A_one_row_data(raw_data_df, 34670891, 13)\n",
    "haha = model_A_inference(result_df, model_A_dict, 'plateau_pressure', feature_columns, 'whole set')\n",
    "print(haha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_B_inference(test_change_label_value_aug_df, model_B_dict, feature, feature_columns, prefix):\n",
    "    regressor = model_B_dict[feature]\n",
    "    regression_predictions = regressor.predict(test_change_label_value_aug_df[feature_columns])\n",
    "    return regression_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_feature_columns = ['before_weaning_hr', 'age_now', 'weight_kg', 'height_cm', 'tobacco', # 'gender', \n",
    "          'peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure',\n",
    "          'peep_prev_1h', 'fio2_prev_1h', 'respiratory_rate_set_prev_1h', 'plateau_pressure_prev_1h',\n",
    "          'heart_rate_prev_1h', 'sbp_prev_1h', 'dbp_prev_1h',\n",
    "          'mbp_prev_1h', 'spo2_prev_1h', 'resp_rate_prev_1h', 'tidal_volume_observed_prev_1h', 'RSBI_prev_1h', 'minute_ventilation_prev_1h',\n",
    "          'heart_rate_prev_2h', 'sbp_prev_2h', 'dbp_prev_2h',\n",
    "          'mbp_prev_2h', 'spo2_prev_2h', 'resp_rate_prev_2h', 'tidal_volume_observed_prev_2h', 'RSBI_prev_2h', 'minute_ventilation_prev_2h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitalsign = ['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', \n",
    "             'tidal_volume_observed', 'RSBI', 'minute_ventilation']\n",
    "ventilator_settings = ['peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure']\n",
    "baseline = ['age_now','gender', 'insurance', 'race', 'admission_type', 'first_careunit'\n",
    ",'weight_kg', 'height_cm', 'tobacco' ]\n",
    "result_df = get_B_one_row_data(raw_data_df, 34670891, 13, model_B_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.7755\n"
     ]
    }
   ],
   "source": [
    "haha2 = model_B_inference(result_df, model_B_dict, 'heart_rate', model_B_feature_columns, 'whole set')\n",
    "print(haha2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_a_patient(df ,stay_id, start_save_hr):\n",
    "    patient_df = patient_df[patient_df['stay_id']==stay_id]\n",
    "    result_df = get_A_one_row_data(df, stay_id, 13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee7d7838ef53998fd22ad7449b76e48b4013ea11e59d28ee193f2cd757746339"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
