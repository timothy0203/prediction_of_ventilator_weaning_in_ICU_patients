{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or '3' to suppress all messages\n",
    "#import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "label_encoder = LabelEncoder()\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'charttime', 'stay_id', 'heart_rate', 'sbp', 'dbp', 'mbp',\n",
      "       'resp_rate', 'spo2', 'peep', 'fio2', 'tidal_volume_observed',\n",
      "       'respiratory_rate_set', 'plateau_pressure', 'GCS', 'age_now', 'gender',\n",
      "       'insurance', 'race', 'admission_type', 'first_careunit', 'tobacco',\n",
      "       'label', 'Rev_h', 'dod_h', 'RSBI', 'minute_ventilation', 'BMI'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "label_path = './data/data_by_table/pre_24h_data_v6.csv'\n",
    "flag_data_path = './data/data_by_table/ground_truth.csv'\n",
    "raw_data_path = './data/data_by_table/pre_24_merged_30_rows_12_07.csv'\n",
    "mode_data_path = './data/data_by_table/pre_24_merged_30_rows_12_07.csv'\n",
    "\n",
    "data_df = pd.read_csv(label_path)\n",
    "flag_data_df = pd.read_csv(flag_data_path)\n",
    "label_df = pd.read_csv(label_path)\n",
    "mode_df = pd.read_csv(mode_data_path)\n",
    "data_df['BMI'] = data_df['weight_kg'] / ((data_df['height_cm'] / 100) ** 2)\n",
    "data_df['gender'] = label_encoder.fit_transform(data_df['gender'])\n",
    "data_df['race'] = label_encoder.fit_transform(data_df['race'])\n",
    "data_df['first_careunit'] = label_encoder.fit_transform(data_df['first_careunit'])\n",
    "data_df['admission_type'] = label_encoder.fit_transform(data_df['admission_type'])\n",
    "#data_df['ventilator_mode_group'] = label_encoder.fit_transform(data_df['ventilator_mode_group'])\n",
    "#data_df['ventilator_mode'] = label_encoder.fit_transform(data_df['ventilator_mode'])\n",
    "data_df['insurance'] = label_encoder.fit_transform(data_df['insurance'])\n",
    "data_df = data_df.drop(columns=['height_cm', 'weight_kg'])\n",
    "data_df['RSBI'] =   data_df['resp_rate']/(data_df['tidal_volume_observed']* 0.001) \n",
    "data_df['minute_ventilation'] = data_df['tidal_volume_observed'] * data_df['resp_rate']* 0.001\n",
    "print(data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    \n",
    "    if df.isna().any().any():\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0 \n",
    "def false_percentage(y_label):\n",
    "    zero = len(y_label) - np.count_nonzero(y_label)\n",
    "    print(f\"false percentage: {(zero/len(y_label)) * 100:.2f}%\")\n",
    "\n",
    "def calculate_tpr_tnr(y_true, y_pred):\n",
    "    # 计算 TP, FN, TN, FP\n",
    "    TP = sum((y_true == 1) & (y_pred == 1))\n",
    "    FN = sum((y_true == 1) & (y_pred == 0))\n",
    "    TN = sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = sum((y_true == 0) & (y_pred == 1))\n",
    "\n",
    "    # 计算 TPR 和 TNR\n",
    "    TPR = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    TNR = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    return TPR, TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(id_df):\n",
    "    label = 0\n",
    "    if not check_missing_values(id_df):\n",
    "            label = id_df['label'].iloc[0]\n",
    "            if label == 1:\n",
    "                label = 48\n",
    "            else:\n",
    "                if id_df['Rev_h'].iloc[0] != -1000:\n",
    "                    label = -(48 - id_df['Rev_h'].iloc[0])\n",
    "                elif id_df['dod_h'].iloc[0] != -1000 and id_df['dod_h'].iloc[0]>0 and id_df['dod_h'].iloc[0]<48:\n",
    "                    label = -(96 - id_df['dod_h'].iloc[0]*2)\n",
    "                else:\n",
    "                    label = -96 \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_columns = ['spo2','peep','heart_rate','respiratory_rate_set','plateau_pressure','tidal_volume_observed','fio2','sbp','dbp','mbp','resp_rate','RSBI','minute_ventilation']\n",
    "\n",
    "def NN_data(flag_data_df, data_df,label_df, mode_df , hour = 23):\n",
    "    total_x = []\n",
    "    total_y = []\n",
    "    count = 0\n",
    "    cc = 0\n",
    "    for index, row in flag_data_df.iterrows():\n",
    "        id_df = data_df[data_df['stay_id'] == row['stay_id']]\n",
    "        id_mode_df = mode_df[mode_df['stay_id'] == row['stay_id']]['ventilator_mode_group']\n",
    "        id_df_label = label_df[label_df['stay_id'] == row['stay_id']]\n",
    "        if not check_missing_values(id_df):\n",
    "            label = get_label(id_df_label)\n",
    "            id_df = id_df.drop(columns='stay_id')\n",
    "            #id_df = id_df.drop(columns='subject_id')\n",
    "            id_df = id_df.drop(columns='label')\n",
    "            id_df = id_df.drop(columns='charttime')\n",
    "            #id_df = id_df.drop(columns='hadm_id')\n",
    "            id_df = id_df.drop(columns='Rev_h')\n",
    "            id_df = id_df.drop(columns='dod_h')\n",
    "            mode_code = 0\n",
    "            #print(id_df.shape)\n",
    "            if(id_df.shape[0] != 24):\n",
    "                continue\n",
    "            zero_hr_values = id_df.iloc[hour, :].values\n",
    "            \n",
    "            try:\n",
    "                count+=1\n",
    "                if(id_mode_df.iloc[-1] == 'Complete Support'):\n",
    "                    mode_code = 1\n",
    "                    cc+=1\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            #zero_hr_values = generate_more_feature(id_df, aug_columns ,zero_hr_values)\n",
    "\n",
    "            zero_hr_values = np.append(zero_hr_values, mode_code)\n",
    "            total_x.append(zero_hr_values)\n",
    "            total_y.append(label)\n",
    "    total_x = np.array(total_x)\n",
    "    total_y = np.array(total_y).reshape(-1, 1)\n",
    "    #print(cc/count*100)\n",
    "    return total_x, total_y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f702e0106652>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlstm_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflag_data_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lstm_data' is not defined"
     ]
    }
   ],
   "source": [
    "lstm_x, lstm_y = lstm_data(flag_data_df, data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_module(X_train, y_train, X_test, y_test, epoch, learning_rate, batch):\n",
    "\n",
    "    # Define model and train\n",
    "    def build_lstm_model(timesteps, num_features):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(128, input_shape=(timesteps, num_features)),\n",
    "            tf.keras.layers.Dense(1) \n",
    "        ])\n",
    "        model.build(input_shape=(None, timesteps, num_features))\n",
    "        return model\n",
    "\n",
    "    model = build_lstm_model(timesteps=X_train.shape[1], num_features=X_train.shape[2])\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss='mean_squared_error') \n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epoch, batch_size=batch, validation_data=(X_test, y_test))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_x, total_y = NN_data(flag_data_df, data_df,label_df, mode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2663, 24)\n",
      "(2130, 24)\n",
      "(2130, 1)\n",
      "Epoch 1/15\n",
      "67/67 [==============================] - 2s 16ms/step - loss: 2969.0464 - val_loss: 2660.5940\n",
      "Epoch 2/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2306.5256 - val_loss: 2095.4038\n",
      "Epoch 3/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2065.2627 - val_loss: 2107.8960\n",
      "Epoch 4/15\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 2040.5266 - val_loss: 2053.3506\n",
      "Epoch 5/15\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 2045.5114 - val_loss: 2029.3732\n",
      "Epoch 6/15\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 1988.4369 - val_loss: 2018.7852\n",
      "Epoch 7/15\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 1982.0592 - val_loss: 2013.3142\n",
      "Epoch 8/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2010.6637 - val_loss: 2024.8434\n",
      "Epoch 9/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2017.2874 - val_loss: 2125.4839\n",
      "Epoch 10/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1965.9915 - val_loss: 2147.1069\n",
      "Epoch 11/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1989.5396 - val_loss: 2001.7484\n",
      "Epoch 12/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1950.4725 - val_loss: 2011.9939\n",
      "Epoch 13/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1957.2354 - val_loss: 1994.9597\n",
      "Epoch 14/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1966.7290 - val_loss: 2034.1604\n",
      "Epoch 15/15\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1948.8378 - val_loss: 1996.9449\n"
     ]
    }
   ],
   "source": [
    "# total_x = lstm_x\n",
    "# total_y = lstm_y\n",
    "total_x = total_x.astype(np.float32)\n",
    "total_y = total_y.astype(np.float32)\n",
    "total_x[np.isinf(total_x)] = np.nan\n",
    "total_x[np.abs(total_x) > 1e6] = np.nan\n",
    "# Handle NaN values by replacing them with zeros (you can choose a different strategy)\n",
    "total_x[np.isnan(total_x)] = 0.0\n",
    "scaler = MinMaxScaler()\n",
    "total_x_normalized = scaler.fit_transform(total_x.reshape(-1, total_x.shape[-1])).reshape(total_x.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(total_x_normalized, total_y, test_size=0.2, random_state=13444332)#4277  433432 4323432\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=4323432)#4277  433432 4323432\n",
    "print(total_x_normalized.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "model = train_NN_module(X_train, y_train, X_test, y_test, epoch=15, learning_rate=0.001, batch=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step\n",
      "TPR: [0.91740413]\n",
      "TNR: [0.42268041]\n",
      "Accuracy: 73.73%\n",
      "AUROC: 0.7308183559894169\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.where(y_pred_proba >0 , 1, 0)\n",
    "y_label = np.where(y_test > 0, 1, 0)\n",
    "y_train_label = np.where(y_train > 0, 1, 0)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_label)\n",
    "tpr, tnr = calculate_tpr_tnr(y_label, y_pred)\n",
    "print(\"TPR:\", tpr)\n",
    "print(\"TNR:\", tnr)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "auroc = roc_auc_score(y_label, y_pred_proba)\n",
    "print(\"AUROC:\", auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false percentage: 36.40%\n",
      "false percentage: 20.64%\n",
      "false percentage: 36.48%\n"
     ]
    }
   ],
   "source": [
    "false_percentage(y_label)\n",
    "false_percentage(y_pred)\n",
    "false_percentage(y_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m roc_curve(y_label, y_pred_proba)\n\u001b[0;32m      2\u001b[0m auroc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_label, y_pred_proba)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, auroc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_label' is not defined"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_label, y_pred_proba)\n",
    "auroc = roc_auc_score(y_label, y_pred_proba)\n",
    "print(\"AUROC:\", auroc)\n",
    "#print(y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"AUC-ROC:\", roc_auc)\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee7d7838ef53998fd22ad7449b76e48b4013ea11e59d28ee193f2cd757746339"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
