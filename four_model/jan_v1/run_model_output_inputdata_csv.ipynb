{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or '3' to suppress all messages\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n",
    "import joblib\n",
    "label_encoder = LabelEncoder()\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = './data/data_by_table/pre_24h_data_v6.csv'\n",
    "flag_data_path = './data/data_by_table/ground_truth.csv'\n",
    "raw_data_path = './data/data_by_table/pre_24h_data_1217.csv'\n",
    "mode_data_path = './data/data_by_table/pre_24_merged_30_rows_12_07.csv'\n",
    "\n",
    "data_df = pd.read_csv(raw_data_path)\n",
    "flag_data_df = pd.read_csv(flag_data_path)\n",
    "label_df = pd.read_csv(label_path)\n",
    "mode_df = pd.read_csv(mode_data_path)\n",
    "data_df['BMI'] = data_df['weight_kg'] / ((data_df['height_cm'] / 100) ** 2)\n",
    "data_df['gender'] = label_encoder.fit_transform(data_df['gender'])\n",
    "data_df['race'] = label_encoder.fit_transform(data_df['race'])\n",
    "data_df['first_careunit'] = label_encoder.fit_transform(data_df['first_careunit'])\n",
    "data_df['admission_type'] = label_encoder.fit_transform(data_df['admission_type'])\n",
    "data_df['ventilator_mode_group'] = label_encoder.fit_transform(data_df['ventilator_mode_group'])\n",
    "data_df['ventilator_mode'] = label_encoder.fit_transform(data_df['ventilator_mode'])\n",
    "data_df['insurance'] = label_encoder.fit_transform(data_df['insurance'])\n",
    "data_df = data_df.drop(columns=['height_cm', 'weight_kg'])\n",
    "data_df['RSBI'] =   data_df['resp_rate']/(data_df['tidal_volume_observed']* 0.001) \n",
    "data_df['minute_ventilation'] = data_df['tidal_volume_observed'] * data_df['resp_rate']* 0.001\n",
    "data_df = data_df.drop(columns=[ 'hadm_id','subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitalsign = ['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', \n",
    "             'tidal_volume_observed', 'RSBI', 'minute_ventilation']\n",
    "ventilator_settings = ['peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure']\n",
    "baseline = ['age_now','gender', 'insurance', 'race', 'admission_type', 'first_careunit'\n",
    ",'weight_kg', 'height_cm', 'tobacco' ]\n",
    "all_feature = ['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', \n",
    "             'tidal_volume_observed', 'RSBI', 'minute_ventilation','peep',\n",
    "              'fio2', 'respiratory_rate_set', 'plateau_pressure','age_now','gender', 'insurance',\n",
    "               'race', 'admission_type', 'first_careunit'\n",
    ",'weight_kg', 'height_cm', 'tobacco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BMI',\n",
       " 'GCS',\n",
       " 'O2_flow',\n",
       " 'Unnamed: 0',\n",
       " 'before_weaning_hr',\n",
       " 'ventilator_mode',\n",
       " 'ventilator_mode_group'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(['Unnamed: 0', 'before_weaning_hr', 'O2_flow', 'heart_rate', 'sbp',\n",
    "       'dbp', 'mbp', 'resp_rate', 'spo2', 'peep', 'fio2',\n",
    "       'tidal_volume_observed', 'respiratory_rate_set', 'plateau_pressure',\n",
    "       'ventilator_mode', 'GCS', 'age_now', 'gender', 'insurance', 'race',\n",
    "       'admission_type', 'first_careunit', 'tobacco', 'RSBI',\n",
    "       'minute_ventilation', 'ventilator_mode_group', 'BMI']) - set(all_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csv(file_name):\n",
    "    data = []\n",
    "    with open(file_name, 'r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            # 將每個元素轉換為數字\n",
    "            row = [int(element) for element in row]\n",
    "            data.append(row[0])\n",
    "    return data\n",
    "\n",
    "group_prefix = 'group_data/1216best/'\n",
    "\n",
    "# 讀取訓練數據\n",
    "train_csv_file = group_prefix + 'train_data_id.csv'\n",
    "train_data_id = read_from_csv(train_csv_file)\n",
    "\n",
    "# 讀取驗證數據\n",
    "val_csv_file = group_prefix + 'val_data_id.csv'\n",
    "val_data_id = read_from_csv(val_csv_file)\n",
    "\n",
    "# 讀取測試數據\n",
    "test_csv_file = group_prefix + 'test_data_id.csv'\n",
    "test_data_id = read_from_csv(test_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_value(df, colname, start, end):\n",
    "    start = 23 - start\n",
    "    end = 23 - end\n",
    "    df = df.reset_index()\n",
    "    return (df[colname].iloc[end] + df[colname].iloc[end-1] + df[colname].iloc[end-2]) - (df[colname].iloc[start] + df[colname].iloc[start+1] + df[colname].iloc[start+2])\n",
    "\n",
    "def get_more_feature(df, colnames, start, end):\n",
    "    add_list = []\n",
    "    for name in colnames:\n",
    "        now = get_diff_value(df, name, start, end)\n",
    "        add_list.append(now)\n",
    "    return np.array(add_list)\n",
    "\n",
    "def false_percentage(y_label):\n",
    "    zero = len(y_label) - np.count_nonzero(y_label)\n",
    "    print(f\"false percentage: {(zero/len(y_label)) * 100:.2f}%\")\n",
    "\n",
    "def calculate_tpr_tnr(y_true, y_pred):\n",
    "    # 计算 TP, FN, TN, FP\n",
    "    TP = sum((y_true == 1) & (y_pred == 1))\n",
    "    FN = sum((y_true == 1) & (y_pred == 0))\n",
    "    TN = sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = sum((y_true == 0) & (y_pred == 1))\n",
    "\n",
    "    # 计算 TPR 和 TNR\n",
    "    TPR = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    TNR = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    return TPR, TNR\n",
    "\n",
    "def calculate_tpr_tnr2(y_true, y_pred):\n",
    "    # 计算 TP, FN, TN, FP\n",
    "    TP = sum((y_true == 1) & (y_pred == 1))\n",
    "    FN = sum((y_true == 1) & (y_pred == 0))\n",
    "    TN = sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = sum((y_true == 0) & (y_pred == 1))\n",
    "\n",
    "    # 计算 TPR 和 TNR\n",
    "    TPR = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    TNR = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    return TPR, TNR\n",
    "\n",
    "def get_label(id_df):\n",
    "    label = 0\n",
    "    if not check_missing_values(id_df):\n",
    "            label = id_df['label'].iloc[0]\n",
    "            if label == 1:\n",
    "                label = 48\n",
    "            else:\n",
    "                if id_df['Rev_h'].iloc[0] != -1000:\n",
    "                    label = -(48 - id_df['Rev_h'].iloc[0])\n",
    "                elif id_df['dod_h'].iloc[0] != -1000 and id_df['dod_h'].iloc[0]>0 and id_df['dod_h'].iloc[0]<48:\n",
    "                    label = -(96 - id_df['dod_h'].iloc[0]*2)\n",
    "                else:\n",
    "                    label = -96 \n",
    "    return label\n",
    "def check_missing_values(df):\n",
    "    \n",
    "    if df.isna().any().any():\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0 \n",
    "def calculate_std_deviation(df, col_name):\n",
    "    selected_col = df[col_name]\n",
    "    std_deviation = selected_col.std()\n",
    "    return std_deviation\n",
    "def calculate_mean_difference(df, col_name):\n",
    "    selected_col = df[col_name]\n",
    "\n",
    "    # 取前三個和最後三個值\n",
    "    first_three_values = selected_col.head(3)\n",
    "    last_three_values = selected_col.tail(3)\n",
    "\n",
    "    # 計算平均值\n",
    "    first_three_mean = first_three_values.mean()\n",
    "    last_three_mean = last_three_values.mean()\n",
    "\n",
    "    # 計算平均值差\n",
    "    mean_difference = last_three_mean - first_three_mean\n",
    "def get_data(flag_data_df, data_df,label_df, mode_df,train_data_id, val_data_id, test_data_id,hour = 23):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    count = 0\n",
    "    cc = 0\n",
    "    all_feature = ['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', \n",
    "             'tidal_volume_observed', 'RSBI', 'minute_ventilation','peep',\n",
    "              'fio2', 'respiratory_rate_set', 'plateau_pressure','age_now','gender',\n",
    "               'race','BMI', 'tobacco','BMI','GCS']\n",
    "    aug_data = ['heart_rate', \n",
    "       'resp_rate', 'spo2', 'peep', 'fio2', 'tidal_volume_observed',\n",
    "       'respiratory_rate_set', 'plateau_pressure']\n",
    "    for index, row in flag_data_df.iterrows():\n",
    "        id_df = data_df[data_df['stay_id'] == row['stay_id']]\n",
    "        id_mode_df = mode_df[mode_df['stay_id'] == row['stay_id']]['ventilator_mode_group']\n",
    "        id_df_label = label_df[label_df['stay_id'] == row['stay_id']]\n",
    "        if not check_missing_values(id_df) or 1:\n",
    "            # label = get_label(id_df_label) # origin have\n",
    "            label = id_df['label']\n",
    "            id_now = id_df['stay_id'].iloc[0]\n",
    "            id_df = id_df[all_feature]\n",
    "            #if(id_df.shape[0] != 24):\n",
    "                #continue\n",
    "                   \n",
    "            #zero_hr_values = id_df.iloc[hour, :].values # origin have\n",
    "            count_complete_mode =  mode_df[mode_df['stay_id'] == row['stay_id']]['ventilator_mode_group'].tail(12).value_counts().get('Complete Support', 0)\n",
    "            #if(id_df.shape[0] != 24):\n",
    "                #continue\n",
    "            \n",
    "            #\"\"\"\n",
    "            #print(id_now)\n",
    "            zero_hr_values = id_now # add \n",
    "            zero_hr_values = np.append(zero_hr_values, id_df.iloc[hour, :].values)\n",
    "            #\"\"\"\n",
    "            #zero_hr_values = id_df.iloc[hour, :].values # origin have\n",
    "            try:\n",
    "                count+=1\n",
    "                if(id_mode_df.iloc[-1] == 'Complete Support'):\n",
    "                    mode_code = 1\n",
    "                    cc+=1\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            #zero_hr_values = np.append(zero_hr_values, mode_code)\n",
    "            zero_hr_values = np.append(zero_hr_values, count_complete_mode)\n",
    "            zero_hr_values = np.append(zero_hr_values, calculate_std_deviation(mode_df[mode_df['stay_id'] == row['stay_id']], 'peep'))\n",
    "            zero_hr_values = np.append(zero_hr_values, calculate_std_deviation(mode_df[mode_df['stay_id'] == row['stay_id']], 'plateau_pressure'))\n",
    "            if id_now in train_data_id:\n",
    "                train_x.append(zero_hr_values)\n",
    "                train_y.append(label)\n",
    "            elif id_now in val_data_id:\n",
    "                val_x.append(zero_hr_values)\n",
    "                val_y.append(label)\n",
    "            elif id_now in test_data_id:\n",
    "                test_x.append(zero_hr_values)\n",
    "                test_y.append(label)\n",
    "    #total_x = np.array(total_x)\n",
    "    #total_y = np.array(total_y).reshape(-1, 1)\n",
    "    #print(cc/count*100)\n",
    "    print(train_x[0])\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.00057070e+07 6.20000000e+01 1.65000000e+02 5.80000000e+01\n",
      " 9.80000000e+01 9.60000000e+01 1.60000000e+01 4.87000000e+02\n",
      " 3.28542094e+01 7.79200000e+00 0.00000000e+00 4.00000000e+01\n",
      " 1.00000000e+01 1.00000000e+01 8.30000000e+01 1.00000000e+00\n",
      " 2.60000000e+01 2.52092014e+01 0.00000000e+00 2.52092014e+01\n",
      " 6.00000000e+00 0.00000000e+00 2.51805078e+00 2.61545019e+00]\n",
      "1860 529 274\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, val_x, val_y, test_x, test_y = get_data(flag_data_df, data_df,label_df, mode_df,train_data_id, val_data_id, test_data_id)\n",
    "print(len(train_x), len(val_x), len(test_x)) #1860 529 274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.00057070e+07 6.20000000e+01 1.65000000e+02 ... 0.00000000e+00\n",
      "  2.51805067e+00 2.61545014e+00]\n",
      " [3.00069830e+07 7.70000000e+01 1.20000000e+02 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.00150100e+07 1.07000000e+02 1.19000000e+02 ... 7.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.99325940e+07 9.60000000e+01 1.32000000e+02 ... 0.00000000e+00\n",
      "  6.08097553e-01 8.58672738e-01]\n",
      " [3.99652060e+07 7.90000000e+01 1.53000000e+02 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.99862060e+07 9.70000000e+01 1.11000000e+02 ... 5.00000000e+00\n",
      "  1.48360610e+00 0.00000000e+00]]\n",
      "(2663, 24)\n",
      "(63912, 1)\n",
      "(1860, 24)\n",
      "(529, 24)\n",
      "(274, 24)\n"
     ]
    }
   ],
   "source": [
    "total_x = train_x+val_x+test_x\n",
    "total_x = np.array(total_x)\n",
    "total_x_stayid = total_x[:, 0]\n",
    "total_x = total_x.astype(np.float32)\n",
    "total_x[np.isinf(total_x)] = np.nan\n",
    "\n",
    "#\"\"\"\n",
    "total_x_nostayid = np.delete(total_x, 0, axis=1)\n",
    "total_x_nostayid[np.abs(total_x_nostayid) > 1e6] = np.nan\n",
    "total_x = np.hstack((total_x_stayid[:, np.newaxis], total_x_nostayid))\n",
    "#\"\"\"\n",
    "#total_x[np.abs(total_x) > 1e6] = np.nan # origin have\n",
    "\n",
    "total_x[np.isnan(total_x)] = 0.0\n",
    "print(total_x)\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = joblib.load('./model/C_scaler.joblib')\n",
    "total_x_normalized = scaler.fit_transform(total_x.reshape(-1, total_x.shape[-1])).reshape(total_x.shape)\n",
    "#joblib.dump(scaler, './model/C_scaler.joblib')\n",
    "\n",
    "X_train = total_x_normalized[:len(train_x)]\n",
    "X_val = total_x_normalized[len(train_x):len(train_x)+len(val_x)]\n",
    "X_test = total_x_normalized[len(train_x)+len(val_x):len(train_x)+len(val_x)+len(test_x)]\n",
    "y_train = np.array(train_y).reshape(-1, 1)\n",
    "y_val = np.array(val_y).reshape(-1, 1)\n",
    "y_test = np.array(test_y).reshape(-1, 1)\n",
    "\n",
    "#\"\"\"\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "#print(total_x_normalized)\n",
    "\n",
    "# df_total_x_normalized = pd.DataFrame(total_x_normalized, columns=['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', \n",
    "#              'tidal_volume_observed', 'RSBI', 'minute_ventilation','peep',\n",
    "#               'fio2', 'respiratory_rate_set', 'plateau_pressure','age_now','gender', \n",
    "#                'race'\n",
    "#                 ,'BMI', 'tobacco','BMI','GCS','count_complete_mode','std peep','std plateau_pressure'])\n",
    "\n",
    "df_total_x = pd.DataFrame(total_x, columns=['stay_id', 'heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', \n",
    "             'tidal_volume_observed', 'RSBI', 'minute_ventilation','peep',\n",
    "              'fio2', 'respiratory_rate_set', 'plateau_pressure','age_now','gender', \n",
    "               'race'\n",
    "                ,'BMI', 'tobacco','BMI','GCS','count_complete_mode','std peep','std plateau_pressure'])\n",
    "total_y = np.concatenate((y_train, y_val, y_test))\n",
    "df_total_y = pd.DataFrame(total_y, columns=['label'])\n",
    "print(df_total_x.shape) # (2663, 23)\n",
    "print(df_total_y.shape) # (2663, 1)\n",
    "\n",
    "total_data = df_total_x.join(df_total_y)\n",
    "total_data.to_csv('0109tryinputmodelC.csv')\n",
    "#\"\"\"\n",
    "\n",
    "print(X_train.shape)\n",
    "#print_percentage_of_negative_values(y_train)\n",
    "print(X_val.shape)\n",
    "#print_percentage_of_negative_values(y_val)\n",
    "print(X_test.shape)\n",
    "#print_percentage_of_negative_values(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def print_classification_metrics(y_true, y_pred, prefix):\n",
    "    print(f\"{prefix} Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "def print_score(model, X_data, y_data, who):\n",
    "    print(\"=========\"+who+\"=========\")\n",
    "    y_pred_proba = model.predict(X_data, verbose=0)\n",
    "    y_pred = np.where(y_pred_proba >0 , 1, 0)\n",
    "    y_label = np.where(y_data > 0, 1, 0)\n",
    "\n",
    "    accuracy = np.mean(y_pred == y_label)\n",
    "    tpr, tnr = calculate_tpr_tnr(y_label, y_pred)\n",
    "    print(\"TPR:\", tpr)\n",
    "    print(\"TNR:\", tnr)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    auroc = roc_auc_score(y_label, y_pred_proba)\n",
    "    print(\"AUROC:\", auroc)\n",
    "    print_classification_metrics(y_label,y_pred, who)\n",
    "def get_score(model, X_data, y_data, who):\n",
    "    y_pred_proba = model.predict(X_data, verbose=0)\n",
    "    y_pred = np.where(y_pred_proba >0 , 1, 0)\n",
    "    y_label = np.where(y_data > 0, 1, 0)\n",
    "\n",
    "    accuracy = np.mean(y_pred == y_label)\n",
    "    tpr, tnr = calculate_tpr_tnr(y_label, y_pred)\n",
    "    auroc = roc_auc_score(y_label, y_pred_proba)\n",
    "    return auroc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========test=========\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1537 predict_step\n        return self(x, training=False)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 23 but received input with shape (None, 24)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5ee2e0862614>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model/modelC_17.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-e1c94e88f6f6>\u001b[0m in \u001b[0;36mprint_score\u001b[1;34m(model, X_data, y_data, who)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=========\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwho\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"=========\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0my_pred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# add\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1749\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1751\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1752\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 760\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3308\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1537 predict_step\n        return self(x, training=False)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\User\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 23 but received input with shape (None, 24)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_test = load_model('./model/modelC_17.h5')\n",
    "print_score(model_test, X_test,y_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-661f5edec83b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 載入模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model/modelC_17.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "from keras.models import load_model\n",
    "\n",
    "# 載入模型\n",
    "model_test = load_model('./model/modelC_17.h5')\n",
    "\n",
    "# 創建 SHAP 解釋器，使用 Independent masker\n",
    "explainer = shap.Explainer(model_test, masker=shap.maskers.Independent(data=X_train), feature_names=['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', 'tidal_volume_observed', 'RSBI', 'minute_ventilation','peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure','age_now','gender', 'race','BMI', 'tobacco','BMI','GCS','count_complete_mode','std peep','std plateau_pressure'])\n",
    "\n",
    "# 提供一個樣本數據（X）以生成 SHAP 值\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 生成 SHAP 圖表\n",
    "shap.summary_plot(shap_values, X_test, feature_names=['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', \n",
    "             'tidal_volume_observed', 'RSBI', 'minute_ventilation','peep',\n",
    "              'fio2', 'respiratory_rate_set', 'plateau_pressure','age_now','gender', \n",
    "               'race'\n",
    "                ,'BMI', 'tobacco','BMI','GCS','count_complete_mode','std peep','std plateau_pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2fdf5cf694df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 載入模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model/1219test.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "from keras.models import load_model\n",
    "\n",
    "# 載入模型\n",
    "model_test = load_model('./model/1219test.h5')\n",
    "\n",
    "# 創建 SHAP 解釋器，使用 Independent masker\n",
    "explainer = shap.Explainer(model_test, masker=shap.maskers.Independent(data=X_train), feature_names=['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', 'tidal_volume_observed', 'RSBI', 'minute_ventilation','peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure','age_now','gender', 'insurance', 'race', 'admission_type', 'first_careunit' ,'BMI', 'tobacco','BMI','GCS'])\n",
    "\n",
    "# 提供一個樣本數據（X）以生成 SHAP 值\n",
    "shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# 生成 SHAP 平均圖表\n",
    "shap.summary_plot(shap_values, X_val, feature_names=['heart_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'resp_rate', 'tidal_volume_observed', 'RSBI', 'minute_ventilation','peep', 'fio2', 'respiratory_rate_set', 'plateau_pressure','age_now','gender', 'insurance', 'race', 'admission_type', 'first_careunit' ,'BMI', 'tobacco','BMI','GCS'], plot_type='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee7d7838ef53998fd22ad7449b76e48b4013ea11e59d28ee193f2cd757746339"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
